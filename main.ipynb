{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 82\u001b[39m\n\u001b[32m     78\u001b[39m train_size = \u001b[32m0.2\u001b[39m  \u001b[38;5;66;03m# Percentage of data for training\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m#test_size = 0.1   # Percentage of data for testing\u001b[39;00m\n\u001b[32m     80\u001b[39m \n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Define transformations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m transform = \u001b[43mtransforms\u001b[49m.Compose([\n\u001b[32m     83\u001b[39m     transforms.Resize((\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)),\n\u001b[32m     84\u001b[39m     transforms.RandomHorizontalFlip(),\n\u001b[32m     85\u001b[39m     transforms.Grayscale(num_output_channels=\u001b[32m3\u001b[39m),\n\u001b[32m     86\u001b[39m     transforms.ToTensor(),\n\u001b[32m     87\u001b[39m ])\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# Load dataset from folder structure\u001b[39;00m\n\u001b[32m     90\u001b[39m dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
      "\u001b[31mNameError\u001b[39m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "## Testing the model by selecting a random image from the image folders\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "def coral_loss(source, target):\n",
    "    \"\"\" Deep CORAL loss to align feature distributions \"\"\"\n",
    "    d = source.size(1)  # Feature dimension\n",
    "    source_coral = torch.matmul((source - source.mean(dim=0)).T, (source - source.mean(dim=0))) / (source.size(0) - 1)\n",
    "    target_coral = torch.matmul((target - target.mean(dim=0)).T, (target - target.mean(dim=0))) / (target.size(0) - 1)\n",
    "    loss = torch.norm(source_coral - target_coral, p='fro')**2 / (4 * d**2)\n",
    "    return loss\n",
    "\n",
    "def new_domain_accuracy(model, new_domain_loader, device):\n",
    "    misclassified_images = []\n",
    "    misclassified_labels = []\n",
    "    misclassified_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in new_domain_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Find misclassified images\n",
    "            misclassified_idx = (predicted != labels).nonzero(as_tuple=True)[0]\n",
    "            for idx in misclassified_idx:\n",
    "                misclassified_images.append(images[idx].cpu())\n",
    "                misclassified_labels.append(labels[idx].cpu())\n",
    "                misclassified_preds.append(predicted[idx].cpu())\n",
    "        print(\"Accuracy for new domain: \"+str((1-len(misclassified_images)/len(new_domain_loader.dataset))*100))\n",
    "\n",
    "\n",
    "def train_domain_adaptation(model, source_loader, target_loader, criterion, optimizer, lambda_coral=0.1, epochs=20):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for (source_images, source_labels), (target_images, _) in zip(source_loader, target_loader):\n",
    "            source_images, source_labels = source_images.to(device), source_labels.to(device)\n",
    "            target_images = target_images.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass for source (labeled)\n",
    "            source_outputs = model(source_images)\n",
    "            classification_loss = criterion(source_outputs, source_labels)\n",
    "\n",
    "            # Forward pass for target (unlabeled)\n",
    "            source_features = model.forward_features(source_images)\n",
    "            target_features = model.forward_features(target_images)\n",
    "\n",
    "            # Flatten spatial features: [32, 512, 7, 7] â†’ [32, 512 * 7 * 7]\n",
    "            source_features = source_features.view(source_features.size(0), -1)\n",
    "            target_features = target_features.view(target_features.size(0), -1)\n",
    "            # Compute CORAL loss\n",
    "            coral_loss_val = coral_loss(source_features, target_features)\n",
    "\n",
    "            # Total loss = classification loss + CORAL loss\n",
    "            loss = classification_loss + lambda_coral * coral_loss_val\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy for source domain\n",
    "            _, predicted = torch.max(source_outputs, 1)\n",
    "            total_samples += source_labels.size(0)\n",
    "            correct_predictions += (predicted == source_labels).sum().item()\n",
    "\n",
    "        avg_loss = total_loss / len(source_loader)\n",
    "        accuracy = correct_predictions / total_samples * 100\n",
    "        new_domain_accuracy(model, test_target_loader, device)\n",
    "        print(f\"TRAINING: Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%, CORAL Loss: {coral_loss_val.item():.4f}\")\n",
    "\n",
    "\n",
    "# Parameters\n",
    "data_dir = '/content/DAPlankton_subset/CS'\n",
    "train_size = 0.4  # Percentage of data for training\n",
    "#test_size = 0.1   # Percentage of data for testing\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),              # Normalize image size\n",
    "    transforms.RandomHorizontalFlip(),          # Add augmentation for robustness\n",
    "    transforms.RandomAffine(degrees=15,         # Slight rotation to reduce sensitivity\n",
    "                            scale=(0.8, 1.2)),  # Random zoom-in/out to balance scale difference\n",
    "    transforms.ColorJitter(brightness=0.2,      # Adjust brightness to balance intensity differences\n",
    "                           contrast=0.2, \n",
    "                           saturation=0.2), \n",
    "    transforms.Grayscale(num_output_channels=3),# Convert all to 3-channel grayscale for consistency\n",
    "    transforms.GaussianBlur(kernel_size=3),     # Reduce sharpness differences\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],  # Normalize pixel intensities\n",
    "                         std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Load dataset from folder structure\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "train_len = int(len(dataset) * train_size)\n",
    "test_len = len(dataset) - train_len\n",
    "train_dataset, test_dataset = random_split(dataset, [train_len, test_len])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model creation\n",
    "num_classes = 3\n",
    "\n",
    "# Load pre-trained ResNet-18 model\n",
    "model = timm.create_model('resnet18', pretrained=True,num_classes=3)\n",
    "\n",
    "# Modify classifier for your dataset\n",
    "#model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "target_data_dir = '/content/DAPlankton_subset/FC'  # Change this to your target domain folder\n",
    "target_dataset = datasets.ImageFolder(root=target_data_dir, transform=transform)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "train_len = int(len(target_dataset) * train_size)\n",
    "test_len = len(target_dataset) - train_len\n",
    "train_target_dataset, test_target_dataset = random_split(target_dataset, [train_len, test_len])\n",
    "\n",
    "# No labels needed, so we replace them with dummy labels\n",
    "train_nolabel_dataset = [(img, -1) for img, _ in train_dataset]\n",
    "\n",
    "train_target_loader = DataLoader(train_nolabel_dataset, batch_size=32, shuffle=True)\n",
    "test_target_loader = DataLoader(test_target_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "train_domain_adaptation(model, train_loader, train_target_loader, criterion, optimizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
